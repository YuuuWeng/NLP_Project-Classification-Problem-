{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":944,"status":"ok","timestamp":1652293536732,"user":{"displayName":"YU Weng","userId":"00576395625376478765"},"user_tz":-600},"id":"8oYd0z0Mk4I2","outputId":"d8b4ef85-986f-4738-ce15-d3ca07e0d4c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed May 11 18:25:35 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!/opt/bin/nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1niOJ4jFPCAQ"},"outputs":[],"source":["import json\n","import os\n","import time\n","import re\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2634,"status":"ok","timestamp":1652293540468,"user":{"displayName":"YU Weng","userId":"00576395625376478765"},"user_tz":-600},"id":"j-lyaO1Gk4I6","outputId":"e4873c4f-c590-41f9-e9ec-5e1528a2d58e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"75t5xy6n-Udn"},"outputs":[],"source":["df_train = pd.read_csv('/content/drive/MyDrive/NLP_task1/train.csv')\n","df_dev = pd.read_csv('/content/drive/MyDrive/NLP_task1/dev.csv')\n","df_test = pd.read_csv('/content/drive/MyDrive/NLP_task1/test.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1652293540469,"user":{"displayName":"YU Weng","userId":"00576395625376478765"},"user_tz":-600},"id":"Y1kk5DALdzBG","outputId":"526c07a9-644f-4bae-9e86-7342fb6fcc07"},"outputs":[{"data":{"text/plain":["label            False\n","text             False\n","retweet_count    False\n","dtype: bool"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df_train.isnull().any()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"njuB_HardWq1"},"outputs":[],"source":["df_train = df_train.dropna(axis=0, how='any')\n","df_dev = df_dev.dropna(axis=0, how='any')\n","# df_test = df_test.dropna(axis=0, how='any')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1652293540470,"user":{"displayName":"YU Weng","userId":"00576395625376478765"},"user_tz":-600},"id":"cPldbJ2_daNk","outputId":"f902f8d0-53a7-47e5-d922-b2ee008e0420"},"outputs":[{"data":{"text/plain":["label            False\n","text             False\n","retweet_count    False\n","dtype: bool"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df_train.isnull().any()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1652293540470,"user":{"displayName":"YU Weng","userId":"00576395625376478765"},"user_tz":-600},"id":"J0dhZ85PgMac","outputId":"e33b6667-9e9e-4864-e431-050d6835603d"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 536 entries, 0 to 535\n","Data columns (total 3 columns):\n"," #   Column         Non-Null Count  Dtype \n","---  ------         --------------  ----- \n"," 0   label          536 non-null    int64 \n"," 1   text           536 non-null    object\n"," 2   retweet_count  536 non-null    int64 \n","dtypes: int64(2), object(1)\n","memory usage: 16.8+ KB\n"]}],"source":["df_dev.info()"]},{"cell_type":"markdown","metadata":{"id":"F9UwtY2QliDM"},"source":["# New Section"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HeNLmPfO6v8c"},"outputs":[],"source":["BERT_BASE = 'bert-base-uncased'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9728,"status":"ok","timestamp":1652293550193,"user":{"displayName":"YU Weng","userId":"00576395625376478765"},"user_tz":-600},"id":"xe0WzOxr6aao","outputId":"23ec7b64-0204-4272-cca8-060b9c7f734d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Done loading BERT model.\n"]}],"source":["!pip install torch torchvision transformers\n","\n","from transformers import BertModel\n","\n","bert_model = BertModel.from_pretrained(BERT_BASE)\n","\n","print(\"Done loading BERT model.\")    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IIOyCgUg63PK"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","from transformers import BertTokenizer\n","import pandas as pd\n","import numpy as np\n","\n","class rumourset(Dataset):\n","\n","    def __init__(self,df,having_label,maxlen):\n","\n","        #Initialize the BERT tokenizer\n","        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","        self.texts = df[\"text\"]\n","        self.having_label = having_label\n","        self.retweet_count = df[\"retweet_count\"]\n","        if having_label:\n","          self.label = df[\"label\"]\n","        self.maxlen = maxlen\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, index):\n","        text = str(self.texts[index])\n","\n","        retweet_count = self.retweet_count[index]\n","\n","        if self.having_label:\n","          label = int(self.label[index])\n","\n","\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.maxlen,\n","            truncation=True,\n","            padding='max_length',\n","            return_attention_mask=True,\n","            return_tensors='pt'\n","        )\n","        \n","        if self.having_label:  \n","          return encoding['input_ids'].flatten(), encoding['attention_mask'].flatten(),encoding['token_type_ids'].flatten(),torch.tensor([int(retweet_count)*5]),torch.tensor([label])\n","        else:\n","          return encoding['input_ids'].flatten(), encoding['attention_mask'].flatten(),encoding['token_type_ids'].flatten(),torch.tensor([int(retweet_count)*5])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1652293550194,"user":{"displayName":"YU Weng","userId":"00576395625376478765"},"user_tz":-600},"id":"E4AUyx7v6i5u","outputId":"e206a4d5-44e4-4e51-b2b1-9c8f79c7dc8f"},"outputs":[{"data":{"text/plain":["0         0\n","1       185\n","2         1\n","3       123\n","4         1\n","       ... \n","1558      1\n","1559     83\n","1560    109\n","1561    177\n","1562      4\n","Name: retweet_count, Length: 1563, dtype: int64"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df_train[\"retweet_count\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4548,"status":"ok","timestamp":1652293554737,"user":{"displayName":"YU Weng","userId":"00576395625376478765"},"user_tz":-600},"id":"Zv2x0pmuDs7C","outputId":"7d107f19-2562-42ab-e73f-ed7e3c538530"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.7.0)\n"]}],"source":["!pip install emoji"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vo1_-8KPPh4e"},"outputs":[],"source":["df_merge = pd.concat([df_train,df_dev])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uI-8WFx58Dh6"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","\n","MAX_LEN = 512\n","BATCH_SIZE = 8\n","NUM_WORKERS = 1\n","SHUFFLE = True\n","\n","train_set = rumourset(df_train, True,maxlen = MAX_LEN)\n","train_loader = DataLoader(train_set, batch_size = BATCH_SIZE,shuffle = SHUFFLE, num_workers = NUM_WORKERS)\n","\n","merge_set = rumourset(df_merge, True,maxlen = MAX_LEN)\n","merge_loader = DataLoader(merge_set, batch_size = BATCH_SIZE,shuffle = SHUFFLE, num_workers = NUM_WORKERS)\n","\n","\n","dev_set = rumourset(df_dev, True,maxlen = MAX_LEN)\n","dev_loader = DataLoader(dev_set, batch_size = BATCH_SIZE,shuffle = SHUFFLE, num_workers = NUM_WORKERS)\n","\n","    \n","    \n","test_set = rumourset(df_test, False,maxlen = MAX_LEN)\n","test_loader = DataLoader(test_set, batch_size = 1,shuffle = False, num_workers = NUM_WORKERS)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9bF13VrX8ltO"},"outputs":[],"source":["## build the bert NN model \n","\n","import torch\n","import torch.nn as nn\n","from transformers import BertModel\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","\n","class RumorClassifier(nn.Module):\n","\n","    def __init__(self):\n","        super(RumorClassifier, self).__init__()\n","        #Instantiating BERT model object \n","        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.linear0 = torch.nn.Linear( 769, 256)\n","        self.linear = torch.nn.Linear( 256, 1)\n","        \n","\n","\n","\n","    def forward(self, encode_text, attn_masks,token_type_ids,retweet_count):\n","        output = self.bert_layer(encode_text, attention_mask = attn_masks, token_type_ids=token_type_ids,return_dict=True)\n","        output_dropout = self.dropout(output.pooler_output)\n","        output = torch.tanh(self.linear0(torch.cat((output_dropout,retweet_count),1)))\n","        output = self.linear(output)\n","        return output\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8204,"status":"ok","timestamp":1652293579826,"user":{"displayName":"YU Weng","userId":"00576395625376478765"},"user_tz":-600},"id":"mXa4CoOG8uBi","outputId":"f5e62e54-ece8-4855-b462-0ee566cbce4c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["\n","gpu = 0 #gpu ID\n","NNbert = RumorClassifier()\n","NNbert.cuda(gpu)\n","\n","## loss function \n","criterion = nn.BCEWithLogitsLoss()\n","\n","## adam optimizer\n","optimizer = optim.Adam(NNbert.parameters(), lr = 2e-5)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3212,"status":"ok","timestamp":1652293583026,"user":{"displayName":"YU Weng","userId":"00576395625376478765"},"user_tz":-600},"id":"x9khDnp5PrPc","outputId":"8705c1f0-8f0a-4c80-82fb-361579f3bb90"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.8.2)\n","Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.11.0+cu113)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n","Requirement already satisfied: pyDeprecate==0.3.* in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (0.3.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.8)\n"]}],"source":["pip install torchmetrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F0k1gJcb8wv_"},"outputs":[],"source":["# the structure of the code is modified from Jey Han Lau. 2021. The Project Specification to 352 COMP90042 Natural Language Processing. The 353 University of Melbourne, Carlton VIC, AU.\n","\n","from torchmetrics.functional import f1_score, recall , precision\n","\n","\n","import time\n","def train(nn_model, criterion, optimizer, train_loader,dev_loader, max_eps, gpu):\n","    best_acc = 0\n","    best_f1score = 0 \n","    st = time.time()\n","    for ep in range(max_eps):\n","        nn_model.train()\n","        \n","        for it, (seq, attn_masks,token_type_ids,retweet_count,labels) in enumerate(train_loader):\n","            #Clear gradients\n","            optimizer.zero_grad()  \n","            #Converting these to cuda tensors\n","            seq, attn_masks,token_type_ids,retweet_count,labels = seq.cuda(gpu), attn_masks.cuda(gpu),token_type_ids.cuda(gpu),retweet_count.cuda(gpu),labels.cuda(gpu)\n","\n","\n","            #Obtaining the output from the model\n","            output = nn_model(seq, attn_masks,token_type_ids,retweet_count)\n","\n","            #Computing loss\n","            loss = criterion(output, labels.float())\n","\n","            #Backpropagating the gradients\n","            loss.backward()\n","\n","            #Optimization step\n","            optimizer.step()\n","              \n","            if it % 100 == 0:\n","                \n","                acc = get_accuracy(output, labels)\n","                print(\"Iteration {} of epoch {} complete. Loss: {}; Accuracy: {}; Time taken (s): {}\".format(it, ep, loss.item(), acc, (time.time()-st)))\n","                st = time.time()\n","\n","        torch.cuda.empty_cache()\n","        dev_acc, dev_loss = evaluate(nn_model, criterion,dev_loader,gpu)\n","        print(\"Epoch {} complete! Development Accuracy: {}; Development Loss: {}\".format(ep, dev_acc,dev_loss))\n","        if dev_acc > best_acc :\n","            print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_acc, dev_acc))\n","            # print(\"Best development f1score improved from {} to {}, saving model...\".format(best_f1score, dev_f1score))\n","            best_acc = dev_acc\n","            # best_f1score = dev_f1score\n","            torch.save(nn_model.state_dict(), 'sstcls_{}.dat'.format(ep))\n","\n","\n","\n","def get_accuracy(output, labels):\n","    probs = torch.sigmoid(output)\n","    soft_probs = (probs > 0.5).long()\n","    acc = (soft_probs == labels).float().mean()\n","    return acc\n","\n","\n","\n","\n","def evaluate(NNbert, criterion, dataloader,gpu):\n","    NNbert.eval()\n","\n","    mean_acc, mean_loss = 0, 0\n","    count = 0\n","\n","\n","    with torch.no_grad():\n","        for seq, attn_masks, token_type_ids,retweet_count,labels in dataloader:\n","            seq, attn_masks,token_type_ids, retweet_count,labels = seq.cuda(gpu), attn_masks.cuda(gpu),token_type_ids.cuda(gpu),retweet_count.cuda(gpu),labels.cuda(gpu)\n","            output = NNbert(seq, attn_masks,token_type_ids,retweet_count)\n","            mean_loss += criterion(output, labels.float()).item()\n","\n","            mean_acc += get_accuracy(output, labels)\n","            count += 1\n","\n","  \n","\n","    return mean_acc / count, mean_loss / count"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1652293583027,"user":{"displayName":"YU Weng","userId":"00576395625376478765"},"user_tz":-600},"id":"b6NdvGib3xnw","outputId":"837e0206-3d62-4d92-875e-9e406eceae40"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |  429550 KB |  429550 KB |  429550 KB |       0 B  |\\n|       from large pool |  428288 KB |  428288 KB |  428288 KB |       0 B  |\\n|       from small pool |    1262 KB |    1262 KB |    1262 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |  429550 KB |  429550 KB |  429550 KB |       0 B  |\\n|       from large pool |  428288 KB |  428288 KB |  428288 KB |       0 B  |\\n|       from small pool |    1262 KB |    1262 KB |    1262 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |  483328 KB |  483328 KB |  483328 KB |       0 B  |\\n|       from large pool |  481280 KB |  481280 KB |  481280 KB |       0 B  |\\n|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   53777 KB |   54552 KB |  265210 KB |  211432 KB |\\n|       from large pool |   52992 KB |   52992 KB |  263168 KB |  210176 KB |\\n|       from small pool |     785 KB |    2042 KB |    2042 KB |    1256 KB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     205    |     205    |     205    |       0    |\\n|       from large pool |      75    |      75    |      75    |       0    |\\n|       from small pool |     130    |     130    |     130    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     205    |     205    |     205    |       0    |\\n|       from large pool |      75    |      75    |      75    |       0    |\\n|       from small pool |     130    |     130    |     130    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      21    |      21    |      21    |       0    |\\n|       from large pool |      20    |      20    |      20    |       0    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      19    |      19    |      20    |       1    |\\n|       from large pool |      18    |      18    |      19    |       1    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.memory_summary(device=None, abbreviated=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"n2TcYp_yGFFF","outputId":"cdda26c4-2209-4250-c519-c0d2f9b1c808"},"outputs":[{"name":"stdout","output_type":"stream","text":["Iteration 0 of epoch 0 complete. Loss: 0.8094308376312256; Accuracy: 0.375; Time taken (s): 1.0006449222564697\n","Iteration 100 of epoch 0 complete. Loss: 1.0072904825210571; Accuracy: 0.75; Time taken (s): 69.60897970199585\n","Epoch 0 complete! Development Accuracy: 0.8190298080444336; Development Loss: 0.38568960486063314\n","Best development accuracy improved from 0 to 0.8190298080444336, saving model...\n","Iteration 0 of epoch 1 complete. Loss: 0.8320029973983765; Accuracy: 0.875; Time taken (s): 88.15421152114868\n","Iteration 100 of epoch 1 complete. Loss: 0.3375263214111328; Accuracy: 0.875; Time taken (s): 73.99794578552246\n","Epoch 1 complete! Development Accuracy: 0.8264924883842468; Development Loss: 0.3493307253985263\n","Best development accuracy improved from 0.8190298080444336 to 0.8264924883842468, saving model...\n","Iteration 0 of epoch 2 complete. Loss: 0.42427974939346313; Accuracy: 0.75; Time taken (s): 93.25970792770386\n","Iteration 100 of epoch 2 complete. Loss: 0.3273555636405945; Accuracy: 0.875; Time taken (s): 77.17971324920654\n","Epoch 2 complete! Development Accuracy: 0.9029850363731384; Development Loss: 0.2753396008664103\n","Best development accuracy improved from 0.8264924883842468 to 0.9029850363731384, saving model...\n","Iteration 0 of epoch 3 complete. Loss: 0.36648744344711304; Accuracy: 1.0; Time taken (s): 94.20527529716492\n","Iteration 100 of epoch 3 complete. Loss: 0.09613591432571411; Accuracy: 0.875; Time taken (s): 77.47594094276428\n","Epoch 3 complete! Development Accuracy: 0.9458954930305481; Development Loss: 0.19965883956026675\n","Best development accuracy improved from 0.9029850363731384 to 0.9458954930305481, saving model...\n","Iteration 0 of epoch 4 complete. Loss: 0.2338777780532837; Accuracy: 1.0; Time taken (s): 94.03433108329773\n","Iteration 100 of epoch 4 complete. Loss: 0.054843563586473465; Accuracy: 1.0; Time taken (s): 77.37185859680176\n","Epoch 4 complete! Development Accuracy: 0.9104477167129517; Development Loss: 0.25478271354657056\n","Iteration 0 of epoch 5 complete. Loss: 0.13663208484649658; Accuracy: 1.0; Time taken (s): 93.41841268539429\n","Iteration 100 of epoch 5 complete. Loss: 0.3230487108230591; Accuracy: 0.875; Time taken (s): 77.30763697624207\n","Epoch 5 complete! Development Accuracy: 0.9570895433425903; Development Loss: 0.13351291331893472\n","Best development accuracy improved from 0.9458954930305481 to 0.9570895433425903, saving model...\n"]}],"source":["num_epoch = 6\n","#fine-tune the model\n","train(NNbert, criterion, optimizer, train_loader,dev_loader,num_epoch,gpu)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nNF0LYq69IoU"},"outputs":[],"source":["def get_predictions(NNbert, test_loader):\n","    NNbert.eval()\n","    out_texts = []\n","    predictions = []\n","\n","    with torch.no_grad():\n","      tweet_ids = []\n","      \n","      for seq, attn_masks,token_type_ids,retweet_count in test_loader:\n","          seq, attn_masks,token_type_ids,retweet_count = seq.cuda(gpu), attn_masks.cuda(gpu),token_type_ids.cuda(gpu),retweet_count.cuda(gpu)\n","          outputs = NNbert(seq,attn_masks,token_type_ids,retweet_count)\n","          probs = torch.sigmoid(outputs)\n","          soft_probs = (probs > 0.5).long()\n","          # tweet_ids.append(tweet_id)\n","          predictions.append(soft_probs)\n","\n","\n","    predictions = torch.stack(predictions).cuda(gpu)\n","\n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"d1AAIDn4kfYx"},"outputs":[],"source":["def get_dev_predictions(NNbert, dev_loader):\n","    NNbert.eval()\n","    out_texts = []\n","    predictions_dev = []\n","    targets =[]\n","\n","    with torch.no_grad():\n","      tweet_ids = []\n","      \n","      for seq, attn_masks,token_type_ids,retweet_count,labels in dev_loader:\n","          seq, attn_masks,token_type_ids,retweet_count,labels = seq.cuda(gpu), attn_masks.cuda(gpu),token_type_ids.cuda(gpu),retweet_count.cuda(gpu),labels.cuda(gpu)\n","          outputs = NNbert(seq,attn_masks,token_type_ids,retweet_count)\n","          probs = torch.sigmoid(outputs)\n","          soft_probs = (probs > 0.5).long()\n","          # tweet_ids.append(tweet_id)\n","          predictions_dev.append(soft_probs)\n","          # print(labels)\n","          targets.append(labels)\n","          # print(targets)\n","          \n","\n","    targets = torch.stack(targets).cuda(gpu)\n","    predictions_dev = torch.stack(predictions_dev).cuda(gpu)\n","\n","    return predictions_dev,targets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"CjKRb0gwkfxh"},"outputs":[],"source":["from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Sic_9lUymevf"},"outputs":[],"source":["predictions_dev, targets = get_dev_predictions(NNbert, dev_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hWZKXTBxyMm0"},"outputs":[],"source":["pre_dev = predictions_dev.cpu().tolist()\n","flat_list_pre1 = [item for sublist in pre_dev for item in sublist]\n","flat_list_pre2 = [item for sublist in flat_list_pre1 for item in sublist]\n","\n","# print(flat_list_pre2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"P31hpYizy4mj"},"outputs":[],"source":["label_dev = targets.cpu().tolist()\n","flat_list_label1 = [item for sublist in label_dev for item in sublist]\n","flat_list_label2 = [item for sublist in flat_list_label1 for item in sublist]\n","# print(flat_list_label2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"72YTwoeTmUId","outputId":"63fc4cc8-a47c-41e8-932d-c7e77e3f06d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.98      0.97      0.97       421\n","           1       0.89      0.91      0.90       115\n","\n","    accuracy                           0.96       536\n","   macro avg       0.93      0.94      0.94       536\n","weighted avg       0.96      0.96      0.96       536\n","\n"]}],"source":["print(classification_report(flat_list_label2,flat_list_pre2,target_names = ['0','1']))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9zmHBXvpit4A"},"outputs":[],"source":["predictions = get_predictions(NNbert, test_loader)\n","\n","def convert_label(num):\n","    if num == 0:\n","        return 'nonrumour'\n","    else:\n","        return 'rumour'\n","\n","prediction_list = predictions.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yvCIcUn8iutP"},"outputs":[],"source":["output= []\n","for prediction in prediction_list:\n","  output.append(prediction[0][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Udth8TrmjPN9"},"outputs":[],"source":["df_result = pd.DataFrame (output, columns = ['predicted'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"trRLJ927lkOS"},"outputs":[],"source":["df_result['Id'] = range(0,len(df_result))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"TxoT7FCbGCpD"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PiZe7kPPlq95"},"outputs":[],"source":["df_result.to_csv('prediction.csv',index = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lSWh1YTOpBUT"},"outputs":[],"source":["df_result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4JGl4NHvyA3m"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"MoreFeaturetask1.ipynb","provenance":[]},"interpreter":{"hash":"1efdf83da36bd9fc32e0556c4f59ed9a03a315f474542f72e7cd76a34233f413"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":0}