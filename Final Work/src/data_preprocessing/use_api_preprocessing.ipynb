{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def twitter_feature_selection(json_file):\n",
    "    selected_feature = {}\n",
    "    selected_feature[\"text\"] = json_file[\"text\"]\n",
    "    # selected_feature[\"id\"] = json_file[\"id\"]\n",
    "    selected_feature[\"created_at\"] = json_file[\"created_at\"]\n",
    "    # selected_feature['like_count'] = json_file['public_metrics']['like_count']\n",
    "    selected_feature['retweet_count'] = json_file['public_metrics']['retweet_count']\n",
    "\n",
    "    # selected_feature[\"hashtag\"] = re.search(r'(\\w+)+', json_file[\"text\"])\n",
    "    return selected_feature\n",
    "\n",
    "def test_feature_selection(json_file):\n",
    "    selected_feature = {}\n",
    "    selected_feature[\"text\"] = json_file[\"text\"]\n",
    "    selected_feature[\"created_at\"] = json_file[\"created_at\"]\n",
    "    selected_feature['retweet_count'] = json_file['retweet_count']\n",
    "\n",
    "    # selected_feature[\"id\"] = json_file[\"id\"]\n",
    "    return selected_feature\n",
    "\n",
    "def convert_label(label):\n",
    "    if label == \"rumour\":\n",
    "        return 1\n",
    "    elif label == \"nonrumour\":\n",
    "        return 0 \n",
    "def merge_dictionary_list(dict_list):\n",
    "      return {\n",
    "    k: [d.get(k) for d in dict_list if k in d]\n",
    "    for k in set().union(*dict_list)\n",
    "  } \n",
    "def remove_unwanted_keys(dict_list, keys):\n",
    "    for item in dict_list:\n",
    "        item.pop(keys, None)\n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    if (file_name == 'train' or file_name == 'dev'):\n",
    "        total_json = []\n",
    "        finished_dict = []\n",
    "        with open(\"/Users/yuweng/Desktop/task1/\" + file_name +\".data.txt\", \"r\") as f:\n",
    "            file_name_event = f.readlines()      \n",
    "        with open(\"/Users/yuweng/Desktop/task1/\" + file_name +\".label.txt\", \"r\") as f:\n",
    "            file_name_label = f.readlines()\n",
    "        for event_str, event_label in zip(file_name_event, file_name_label):\n",
    "            event_list = event_str.rstrip().split(\",\")\n",
    "            event_label = event_label.rstrip().split(\",\")\n",
    "            event_json = []\n",
    "            path = \"/Users/yuweng/Desktop/task1/\" + file_name +'/' + event_list[0] + \".json\"\n",
    "            # print(path)\n",
    "            # print(os.path.exists(path))\n",
    "            if os.path.exists(path):\n",
    "                for id in event_list:\n",
    "                    path = \"/Users/yuweng/Desktop/task1/\" + file_name +'/' + id + \".json\"\n",
    "                    # print(path)\n",
    "                    # print(os.path.exists(path))\n",
    "                    if os.path.exists(path):\n",
    "                        related_tweet = json.load(open(path, \"r\"))\n",
    "                        # print(related_tweet)\n",
    "                        event_json.append(twitter_feature_selection(related_tweet))\n",
    "                        # print(event_json)\n",
    "                event_json = sorted(event_json, key=lambda x: time.mktime(time.strptime(x[\"created_at\"], '%Y-%m-%dT%H:%M:%S.%fZ')))\n",
    "                event_json.append({\"label\":convert_label(''.join(event_label))})\n",
    "                # print(event_json)\n",
    "                merged_dict = merge_dictionary_list(event_json)\n",
    "                # print(merged_dict)\n",
    "                total_json.append(merged_dict)\n",
    "                # print(total_json)\n",
    "                finished_dict = remove_unwanted_keys(total_json, \"created_at\")\n",
    "    elif (file_name == 'test'):\n",
    "        total_json = []\n",
    "        finished_dict = []\n",
    "        with open(\"/Users/yuweng/Desktop/task1/\" + file_name +\".data.txt\", \"r\") as f:\n",
    "            file_name_event = f.readlines()      \n",
    "        for event_str in file_name_event:\n",
    "            event_list = event_str.rstrip().split(\",\")\n",
    "            event_json = []\n",
    "            path = \"/Users/yuweng/Desktop/task1/\" + file_name +'/' + event_list[0] + \".json\"\n",
    "            # print(path)\n",
    "            # print(os.path.exists(path))\n",
    "            if os.path.exists(path):\n",
    "                for id in event_list:\n",
    "                    path = \"/Users/yuweng/Desktop/task1/\" + file_name +'/' + id + \".json\"\n",
    "                    # print(path)\n",
    "                    # print(os.path.exists(path))\n",
    "                    if os.path.exists(path):\n",
    "                        related_tweet = json.load(open(path, \"r\"))\n",
    "                        # print(related_tweet)\n",
    "                        event_json.append(test_feature_selection(related_tweet))\n",
    "                event_json = sorted(event_json, key=lambda x: time.mktime(time.strptime(x[\"created_at\"], '%a %b %d %H:%M:%S %z %Y')))\n",
    "                # print(event_json)\n",
    "                merged_dict = merge_dictionary_list(event_json)\n",
    "                # print(merged_dict)\n",
    "                total_json.append(merged_dict)\n",
    "                # print(total_json)\n",
    "                finished_dict = remove_unwanted_keys(total_json, \"created_at\")\n",
    "    return pd.DataFrame(finished_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Required data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_data(\"train\")\n",
    "df_dev = load_data(\"dev\")\n",
    "df_test = load_data(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(tweet):\n",
    "    r1 = r'https?:/\\/\\S+'\n",
    "    ## remove @people\n",
    "    r2 = r'@[a-zA-Z0-9’!\"#$%&\\'()*+,-./:;<=>?@，。?★、…？“”‘’！\\\\]+'\n",
    "    ##remove tag\n",
    "    r3 = r'#[a-zA-Z0-9’!\"#$%&\\'()*+,-./:;<=>?@，。?★、…？“”‘’！\\\\]+'\n",
    "\n",
    "    tweet = tweet.encode('utf-8', 'replace').decode('utf-8')\n",
    "    tweet = re.sub(r1, \"\", tweet)\n",
    "    tweet = re.sub(r2, \"\", tweet)\n",
    "    tweet = re.sub(r3, \"\", str(tweet).lower().strip())\n",
    "    return tweet\n",
    "def give_emoji_free_text(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\" \n",
    "        u\"\\U0001F300-\\U0001F5FF\" \n",
    "        u\"\\U0001F680-\\U0001F6FF\" \n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "        u\"\\U0001F1F2-\\U0001F1F4\"  \n",
    "        u\"\\U0001F1E6-\\U0001F1FF\" \n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U0001F1F2\"\n",
    "        u\"\\U0001F1F4\"\n",
    "        u\"\\U0001F620\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'', text)\n",
    "def remove_html(text):\n",
    "    html = re.compile(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    return re.sub(html, '', text)\n",
    "def remove_punct(text):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(table).strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the Text together and do the data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Can regularly rinsing your nose with saline help prevent infection with the new coronavirus? #COVID19 #21daysLockdownSA https://t.co/amR7IPw2C6',\n",
       " \"@GP_CommSafety Hold on a bit and tell us why this virus after there was a movie of it? If you knew it was coming true then why didn't you find it's cure before now, you think lockdown will help? And how????? https://t.co/6ysbe4qFE6\",\n",
       " '@GP_CommSafety Remove this post please']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev['text'][21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['text'] = df_train.apply(lambda x:text_preprocessing(''.join(x[\"text\"])),axis=1)\n",
    "# df_train['text'] = df_train['text'].apply(lambda x:x.lower().replace('\\n',''))\n",
    "# df_train['text'] = df_train['text'].apply(lambda x:give_emoji_free_text(x))\n",
    "p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.MENTION,p.OPT.RESERVED,p.OPT.EMOJI,p.OPT.SMILEY,p.OPT.NUMBER)\n",
    "df_train.text = df_train.text.apply(lambda x : ''.join(x))\n",
    "df_train.text = df_train.text.apply(lambda x : p.clean(x))\n",
    "df_train['text'] = df_train['text'].apply(lambda x:x.lower().replace('\\n','').replace(\"#\", \"\"))\n",
    "\n",
    "df_train['label'] = df_train.apply(lambda x:x[\"label\"][0],axis=1)\n",
    "df_train['label'] = df_train['label'].astype('int')\n",
    "df_train['retweet_count'] = df_train.apply(lambda x:sum(x[\"retweet_count\"]),axis=1)\n",
    "\n",
    "# df_dev['text'] = df_dev.apply(lambda x:text_preprocessing(''.join(x[\"text\"])),axis=1)\n",
    "\n",
    "# df_dev['text'] = df_dev['text'].apply(lambda x:give_emoji_free_text(x))\n",
    "df_dev.text = df_dev.text.apply(lambda x : ''.join(x))\n",
    "df_dev.text = df_dev.text.apply(lambda x : p.clean(x))\n",
    "df_dev['text'] = df_dev['text'].apply(lambda x:x.lower().replace('\\n','').replace(\"#\", \"\"))\n",
    "df_dev['label'] = df_dev.apply(lambda x:x[\"label\"][0],axis=1)\n",
    "df_dev['label'] = df_dev['label'].astype('int')\n",
    "df_dev['retweet_count'] = df_dev.apply(lambda x:sum(x[\"retweet_count\"]),axis=1)\n",
    "\n",
    "# df_test['text'] = df_test.apply(lambda x:text_preprocessing(''.join(x[\"text\"])),axis=1)\n",
    "# df_test['text'] = df_test['text'].apply(lambda x:x.lower().replace('\\n',''))\n",
    "# df_test['text'] = df_test['text'].apply(lambda x:give_emoji_free_text(x))\n",
    "df_test.text = df_test.text.apply(lambda x : ''.join(x))\n",
    "# p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.RESERVED, p.OPT.EMOJI, p.OPT.SMILEY, p.OPT.NUMBER)\n",
    "df_test.text = df_test.text.apply(lambda x : p.clean(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x:x.lower().replace('\\n','').replace(\"#\", \"\"))\n",
    "df_test['retweet_count'] = df_test.apply(lambda x:sum(x[\"retweet_count\"]),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df_train['text'] = df_train['text'].apply(lambda x:remove_URL(x))\n",
    "\n",
    "# df_train['text'] = df_train['text'].apply(lambda x:remove_html(x))\n",
    "# df_train['text'] = df_train['text'].apply(lambda x:remove_punct(x))\n",
    "\n",
    "# df_dev['text'] = df_dev['text'].apply(lambda x:remove_URL(x))\n",
    "\n",
    "# df_dev['text'] = df_dev['text'].apply(lambda x:remove_html(x))\n",
    "# df_dev['text'] = df_dev['text'].apply(lambda x:remove_punct(x))\n",
    "\n",
    "# df_test['text'] = df_test['text'].apply(lambda x:remove_URL(x))\n",
    "\n",
    "# df_test['text'] = df_test['text'].apply(lambda x:remove_html(x))\n",
    "# df_test['text'] = df_test['text'].apply(lambda x:remove_punct(x))\n",
    "\n",
    "# df_train = df_train.dropna(axis=0, how='any')\n",
    "# df_dev = df_dev.dropna(axis=0, how='any')\n",
    "# df_test = df_test.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google south american goliath birdeater. helllll noooooo they just keep finding stuff not fallin for that again nasty!!!!!! no reason it should even exist ok nooooo wtf a puppy sized spiderthis is the spider : google south american goliath birdeater. helllll noooooo no no no no no no! that\\'s a horror movie spider! lol! i\\'m the same way with rats.... i thought it was going to be a bird byeeeee : google south american goliath birdeater. helllll noooooo i just cringed!!!\": google south american goliath birdeater. helllll noooooo\" why would you do this to me? hence why i\\'m arachnophobic!!!! .. : google south american goliath birdeater. helllll noooooo gurllll. i got one for you. google camel spider. omg ah i hate you... my curiosity got the best of me hahahaha fuck u why would u make me: google south american goliath birdeater. helllll noooooo: google south american goliath birdeater. helllll noooooo omg i noped that so hard! i threw my phone across the room fuck you omg lol holy balls!!! that\\'s a big ass spider : google south american goliath birdeater. helllll noooooo : google south american goliath birdeater. helllll noooooo do it wherever it lives just got added to my never want to visit list : google south american goliath birdeater. helllll noooooo ewwwwwwwww! i\\'m scared of spiders the size of a dime nogodno traumatized: google south american goliath birdeater. helllll noooooo that is a fuck no (good god almighty)! you should try google camel spider why why wwwhhhyyy would u do that to us??? i think i just pissed my pants...: google south american goliath birdeater. helllll noooooo what the actual fuck that shit!!: google south american goliath birdeater. helllll noooooo if i ever saw one id just go ahead &amp; die: google south american goliath birdeater. helllll noooooo i hate you for that!!!! : google south american goliath birdeater. helllll noooooo joda noooo tire el celular: google south american goliath birdeater. helllll noooooo all aboard the nope train! : google south american goliath birdeater. helllll noooooo i wanna do it but i\\'m scared! ew!!!: google south american goliath birdeater. helllll noooooo bye omg no thanks for that. : google south american goliath birdeater. helllll noooooo i\\'d rather die than see that holy shit. ew. no no no no no no no no no no. annnnnd i now need to change the bed... hugeassspider puppysize atethepuppy bedshittage omg i literally stopped breathing!! ...ewweww....no way did you watch the video on youtube? it\\'s really interesting. i think you will do great,bc you and jenny are great in front of the camera..good luck ew! why would you do that?! shame on you i kinda do what ever you tell me sooo....... that was not pretty omggg i literally have goosebumps from googling that ugly thing! i just had a tick crawling on my shirt just almost died : google south american goliath birdeater. helllll noooooo'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev['text'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how does covid-19 spread? thanks, wcco! you ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if you dont believe me, all you have to do is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q. how are covid-19 and influenza viruses simi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>una de les q&amp;amp;a on coronaviruses de la pgin...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we cant forget that racism is in all our insti...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>ex-marlboro man dies from smoking-related dise...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>holy shit. doritos flavored mountain dew. all ...</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>banksy account joins cartoonists support for c...</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>q: who are the members and advisers of the int...</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>can covid-19 be caught from a person who has n...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  retweet_count\n",
       "0    how does covid-19 spread? thanks, wcco! you ar...              0\n",
       "1    if you dont believe me, all you have to do is ...              0\n",
       "2    q. how are covid-19 and influenza viruses simi...              0\n",
       "3    una de les q&amp;a on coronaviruses de la pgin...              5\n",
       "4    we cant forget that racism is in all our insti...              6\n",
       "..                                                 ...            ...\n",
       "553  ex-marlboro man dies from smoking-related dise...            140\n",
       "554  holy shit. doritos flavored mountain dew. all ...            182\n",
       "555  banksy account joins cartoonists support for c...            351\n",
       "556  q: who are the members and advisers of the int...             69\n",
       "557  can covid-19 be caught from a person who has n...              3\n",
       "\n",
       "[558 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>. can eating garlic help prevent infection wit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>french police chief killed himself after charl...</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>coronavirus disease (covid-19) advice for the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ottawa police confirm that there were multiple...</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>if the primary focus of a government isn't to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>0</td>\n",
       "      <td>. it cannot be transmitted through goods manuf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>1</td>\n",
       "      <td>desperate ted cruz claims planned parenthood s...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>1</td>\n",
       "      <td>\"thoughts and prayers are not enough.\" pres. o...</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>0</td>\n",
       "      <td>police have surrounded this building where the...</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>0</td>\n",
       "      <td>excellent. tasha and i just little giggle at t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1563 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  retweet_count\n",
       "0         0  . can eating garlic help prevent infection wit...              0\n",
       "1         1  french police chief killed himself after charl...            185\n",
       "2         0  coronavirus disease (covid-19) advice for the ...              1\n",
       "3         0  ottawa police confirm that there were multiple...            123\n",
       "4         0  if the primary focus of a government isn't to ...              1\n",
       "...     ...                                                ...            ...\n",
       "1558      0  . it cannot be transmitted through goods manuf...              1\n",
       "1559      1  desperate ted cruz claims planned parenthood s...             83\n",
       "1560      1  \"thoughts and prayers are not enough.\" pres. o...            109\n",
       "1561      0  police have surrounded this building where the...            177\n",
       "1562      0  excellent. tasha and i just little giggle at t...              4\n",
       "\n",
       "[1563 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('train.csv', index=False)\n",
    "df_dev.to_csv('dev.csv', index = False)\n",
    "df_test.to_csv('test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/Users/yuweng/Desktop/task1/train.csv')\n",
    "df_dev = pd.read_csv('/Users/yuweng/Desktop/task1/dev.csv')\n",
    "df_test = pd.read_csv('/Users/yuweng/Desktop/task1/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label            False\n",
       "text             False\n",
       "retweet_count    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text              True\n",
       "retweet_count    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(axis=0, how='any', inplace=True)\n",
    "df_dev.dropna(axis=0, how='any', inplace=True)\n",
    "# df_test.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_NaN = df_test.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = df_test[row_has_NaN]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "553    False\n",
       "554    False\n",
       "555    False\n",
       "556    False\n",
       "557    False\n",
       "Length: 558, dtype: bool"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_has_NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"train.csv\",index= False)\n",
    "df_dev.to_csv('dev.csv',index= False)\n",
    "df_test.to_csv('test.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how does covid-19 spread? thanks, wcco! you ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if you dont believe me, all you have to do is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q. how are covid-19 and influenza viruses simi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>una de les q&amp;amp;a on coronaviruses de la pgin...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we cant forget that racism is in all our insti...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>ex-marlboro man dies from smoking-related dise...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>holy shit. doritos flavored mountain dew. all ...</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>banksy account joins cartoonists support for c...</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>q: who are the members and advisers of the int...</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>can covid-19 be caught from a person who has n...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  retweet_count\n",
       "0    how does covid-19 spread? thanks, wcco! you ar...              0\n",
       "1    if you dont believe me, all you have to do is ...              0\n",
       "2    q. how are covid-19 and influenza viruses simi...              0\n",
       "3    una de les q&amp;a on coronaviruses de la pgin...              5\n",
       "4    we cant forget that racism is in all our insti...              6\n",
       "..                                                 ...            ...\n",
       "553  ex-marlboro man dies from smoking-related dise...            140\n",
       "554  holy shit. doritos flavored mountain dew. all ...            182\n",
       "555  banksy account joins cartoonists support for c...            351\n",
       "556  q: who are the members and advisers of the int...             69\n",
       "557  can covid-19 be caught from a person who has n...              3\n",
       "\n",
       "[558 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1efdf83da36bd9fc32e0556c4f59ed9a03a315f474542f72e7cd76a34233f413"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
